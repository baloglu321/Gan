{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25a151e-1558-4ba2-8b1e-94f924381ccd",
   "metadata": {},
   "source": [
    "<h2> Generating Faces With A WGan </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dff3893-14f4-49cf-acb9-57d1fa794e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import PIL\n",
    "import pdb\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031c433f-7d18-4f9b-91b9-33365351603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(tensor,num=25,name=''):\n",
    "    data=tensor.detach().cpu()\n",
    "    grid=make_grid(data[:num],nrow=5).permute(1,2,0)\n",
    "    plt.imshow(grid.clip(0,1))\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b083106-6ccc-4161-869a-f2460a25955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters and general parameters\n",
    "n_epochs=10000\n",
    "batchsize=128\n",
    "lr=1e-4\n",
    "zdim=200\n",
    "device='cuda'\n",
    "\n",
    "cur_step=0\n",
    "crit_cycles=5\n",
    "gen_losses=[]\n",
    "crit_losses=[]\n",
    "show_step=35\n",
    "save_step=35\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e456ca07-afa7-48b3-a23e-97860550b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator model\n",
    "#n=>Input image width/height (or feature map channels for later layers)\n",
    "#stride=> Stride of the kernel in the convolutional layer\n",
    "#padding=>Padding applied to the input borders in the convolutional layer (e.g., 'same' or 'valid')\n",
    "#ks=> Kernel size: Size of the convolutional kernel (filter)\n",
    "#nn.ConvTranspose2d :(n-1)*stride-2*padding+ks\n",
    "#nn.Conv2d : (n+2*pad-ks)//stride+1\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim=64,d_dim=16):\n",
    "        super (Generator,self).__init()\n",
    "        self.z_dim=z_dim\n",
    "        #we begin with a 1x1 image with z_dim number of channels (200)\n",
    "        self.gen=nn.sequential(\n",
    "            nn.ConvTranspose2d(z_dim,d_dim*32,kernel_size=4,stride=1,padding=0), #(((1-1)*1)-2*0)+4=4 so size 4x4 and (ch=200(z_dim),512(d_dim*32))\n",
    "            nn.BatchNorm2d(d_dim*32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(d_dim*32,d_dim*16,kernel_size=4,stride=2,padding=1),#(((4-1)*2)-2*1)+4=8 so size 8x8 and (ch=512(d_dim*32),256(d_dim*16))\n",
    "            nn.BatchNorm2d(d_dim*16),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(d_dim*8,d_dim*4,kernel_size=4,stride=2,padding=1),#(((16-1)*2)-2*1)+4=32 so size 32x32 and (ch=128(d_dim*8),64(d_dim*4))\n",
    "            nn.BatchNorm2d(d_dim*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(d_dim*4,d_dim*2,kernel_size=4,stride=2,padding=1),#(((32-1)*2)-2*1)+4=64 so size 64x64 and (ch=64(d_dim*4),32(d_dim*2))\n",
    "            nn.BatchNorm2d(d_dim*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(d_dim*2,3,kernel_size=4,stride=2,padding=1),#(((64-1)*2)-2*1)+4=128 so size 128x128 and (ch=32(d_dim*2),3)\n",
    "            nn.Tanh() #Produce result in the range from -1 to 1\n",
    "                       \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,noise):\n",
    "        x=noise.view(len(noise),self.z_dim,1,1) #128x200x1x1\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "\n",
    "def gen_noise(num,z_dim,device='cuda'):\n",
    "    return torch.randn(num,z_dim,device=device)#128x200\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576663b3-3c07-4faa-8343-bc90c87241c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic model\n",
    "#conv2d: in_channels, out_channels,kernel_size,stride=1,padding=0\n",
    "#new width and height: #(n+2*pad-ks)//stride+1\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self,d_dim=16):\n",
    "        super(Critic,self).__init__()\n",
    "        self.crit=nn.Sequential(\n",
    "        #conv2d: in_channels, out_channels,kernel_size,stride=1,padding=0\n",
    "        #new width and height: #(n+2*pad-ks)//stride+1\n",
    "        nn.Conv2d(3,d_dim,kernel_size=4,stride=2,padding=1), #(128+2*1-4)//2+1=64 so new size 64x64 and ch:(3,16(d_dim))\n",
    "        nn.InstanceNorm2d(d_dim),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(d_dim,d_dim*2,kernel_size=4,stride=2,padding=1), #(64+2*1-4)//2+1=32 so new size 32x32 and ch:(16(d_dim),32(d_dim*2))\n",
    "        nn.InstanceNorm2d(d_dim*2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(d_dim*2,d_dim*4,kernel_size=4,stride=2,padding=1), #(32+2*1-4)//2+1=16 so new size 16x16 and ch:(32(d_dim*2),64(d_dim*4))\n",
    "        nn.InstanceNorm2d(d_dim*4),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(d_dim*4,d_dim*8,kernel_size=4,stride=2,padding=1), #(16+2*1-4)//2+1=8 so new size 8x8 and ch:(64(d_dim*4),128(d_dim*8))\n",
    "        nn.InstanceNorm2d(d_dim*8),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        \n",
    "        nn.Conv2d(d_dim*8,d_dim*16,kernel_size=4,stride=2,padding=1), #(8+2*1-4)//2+1=4 so new size 4x4 and ch:(128(d_dim*8),256(d_dim*16))\n",
    "        nn.InstanceNorm2d(d_dim*16),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(d_dim*16,1,kernel_size=4,stride=1,padding=0), #(4+2*1-4)//2+0=1 so new size 1x1 and ch:(256(d_dim*16),1)\n",
    "       )\n",
    "    def forward(self,image):\n",
    "       #image:128x3x128x128\n",
    "        crit_pred=self.crit(image) #128x1x1x1   batch size x channel x widht x height\n",
    "        return crit_pred.view(len(crit_pred),-1) #128x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e99b33-7f85-4277-be6a-4dfe05505242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
